mode:
    'classification'

architecture:
    criterion: 'cross_entropy'
    to_vec: True
    d_input: 30522  # vocab_size or num_embedding using BertTokenizer.from_pretrained('bert-base-uncased')
    kernel_size: 4096
    d_output: 2

learning:
    val_split: 0.02